# Load Balancing

트래픽에 대처할 수 있는 방법으로는 2가지가 있다
1. Scale Up: 서버자체의 성능을 높이는 것.
2. Scale Out: 여러 대의 서버를 두는것인데 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드 밸런싱이 꼭 필요하다.

## (Load Balancing) 로드 밸런싱
- 둘 이나 셋 이상의 중앙처리장치, 저장장치와 같은 컴퓨터 자원들에게 작업(work), 부하 (Load)를 나누는것을 의미  
서버 하나가 일을 다 처리하면 부담스러우니 여러서버한테 일을 나누겠다 
- 즉 밸런스를 맞춰 일을 진행하겠다는 것

![정리3](https://github.com/Nomad-CS-STUDY/CS_STUDY/assets/71619429/76ca1f2d-ab4b-4719-bad8-db63d6eb2f7a)

그림과 같이 Load Balacer는 Client의 요청 및 네트워크 의 트래픽이 집중되는 서버들( Server Farm/ Server Pool) 또는 네트워크 허브 사이에 위치하여, 특정 서버 또는 네트워크 허브가 부하가 집중되지 않도록 트래픽을 분산시키는 역할을 한다.

## Load Balancing 의 기본기능

1. Health Check (상태 확인) 
서버들에 대한 주기적인 Health Check를 통해 서버들의 장애 여부를 판단하여 정상동작 중인 서버로만 트래픽을 보낸다.
- L3 Check : ICMP를 이용하여 서버의 IP 주소가 통신 가능한 상태인지를 확인
- L4 Check: TCP 는 3 Way-Handshaking을 기반으로 통신하는데 TCP의 특성을 바탕으로 각 포트상태를 체크하는것 
- L7 Check: Application 계층에서 체크를 수행. 실제 윕페이지에 통신을 시도하여 이상 유뮤를 파악 

2. Tunneling (터널링)
- 데이터 스트림을 인터넷 상에서 가상의 파이프를 통해 전달시키는 기술로, 패킷 내에 터널링할 대상을 캡슐화시켜 목적지까지 전송.
- 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제하게 함.

3. NAT (Network Address Translation)
- 내부 네트워크에서 사용하는 사설 IP 주소와 로드밸런서 외부의 공인 IP 주소 간의 변환 역할.
- 로드밸런싱 관점에서는 여러 개의 호스트가 하나의 공인 IP 주소(VLAN or VIP)를 통해 접속하는 것이 주 목적.
- SNAT (Source Network Address Translation) : 내부에서 외부로 트래픽이 나가는 경우.
내부 사설 IP 주소 -> 외부 공인 IP 주소로 변환.
- DNAT (Destination Network Address Translation) : 외부에서 내부로 트래픽이 들어오는 경우.
외부 공인 IP 주소 -> 내부 사설 IP 주소로 변환.

4. DSR (Destination Network Address Translation)
- 서버에서 클라이언트로 트래픽이 되돌아가는 경우, 목적지를 클라이언트로 설정한 다음, 네트워크 장비나 로드밸런서를 거치지 않고 바로 클라이언트를 찾아가는 방식. 
- 이 기능을 통해 로드밸런서의 부하를 줄여줄 수 있음.
(ICMP : Internet Control Message Protocol. 패킷 전송에 실패했을 때 에러가 났음을 알림과 동시에, 해결 가능한 힌트를 제공하는 메시징 프로토콜. TCP/IP의 IP 계층에서 동작.)

## 로드 밸런싱과 관련하여 면접에서 언급 될 수 있는 질문과 답변 (+ 개념정리)

### 1 .  로드 밸런싱(Load Balancing) 에 대해 말해보세요.

 

A)   로드 밸런싱은 주로 서버 구축 및 활용 시에 고려하는데요. 간단하게 말씀드리면 서버에 가해지는 부하를 적절하게 분산시켜주는 장치 또는 기술을 뜻합니다. 처음에 구축했던 서버가 수용할 수 있는 범위보다 더 큰 트래픽으로 기존 서버를 사용할 수 없게 되는 경우가 있습니다. 이 때 서버 트래픽을 분산시키기 위해 사용합니다.

 

 


로드 밸런싱 (출처 : https://msandbu.org/deep-dive-azure-load-balancer)
 

 

### 2 .  서버 확장의 두 가지 방법(Scale-Up, Scale-Out) 에 대해 설명해보세요.

 

A)  Scale-Up 방식은 서버 자체의 성능을 향상시키는 것으로, 서버 CPU, RAM 등을 교체하여 서버의 성능을 향상시킵니다.

반면, Scale-Out 방식은 기존 서버와 동일하거나 낮은 서버를 여러 대 증설하여 운영하는 것을 뜻합니다. 보통 Scale-Out 방식을 사용하는데, 그 이유는 서버 성능을 향상시키는 것보다 여러 대의 서버를 증설하는 것이 비용적 측면에서 효과적이기 때문입니다.

 

 

 

 
 

### 3 .  로드 밸런싱 알고리즘 중 대표적인 라운드 로빈, 최소 연결 방식 에 대해 설명해보세요.

 

A)   라운드 로빈(Round Robin) 알고리즘은 서버에 들어오는 요청들을 순서대로 돌아가면서 배정하는 알고리즘입니다. 뭐가되었든 하나씩 배정하기 때문에 여러 대의 서버 성능이 비슷하고 세션이 오래 지속되지 않는 경우에 적합합니다.

 

반면, 최소 연결 방식(Least Connection Method) 은 요청이 서버에 들어왔을 때 가장 연결이 적은 서버에 배정하는 알고리즘입니다. 서버 트래픽이 일정하지 않고 세션이 길어질 때 적합합니다.

 

이 외에도 서버마다 가중치를 매겨 가중치에 맞게 요청을 배정하는 가중 라운드 로빈 방식, 클라이언트의 IP주소를 해싱하여 분배하는 IP 해싱 방식, 서버의 현재 연결 상태와 응답 시간을 고려하여 배분하는 최소 리스폰 타임 알고리즘이 있습니다.

 

 

### 4 .  L4 로드 밸런싱과 L7 로드 밸런싱에 대해 설명하고, 차이를 말해보세요.

 

A)   L4 로드 밸런싱은 Layer 4(네트워크 계층 또는 트랜스포트(전송) 계층) 의 정보를 바탕으로 트래픽을 분산하는 방식입니다. 즉, TCP, UDP, IP 정보들을 바탕으로 분산하는데요. 이는 정보가 어떻게 생겼는지 보지 않고 패킷 레벨에서만 트래픽을 분산하기 때문에 속도가 빠르고 효율성이 높습니다. 그리고 L7 로드 밸런싱보다 저렴합니다.

 

반면, L7 로드 밸런싱은 Layer 7(애플리케이션(응용) 계층) 의 정보를 바탕으로 요청을 분산합니다. HTTP Header, Cookie 등과 같이 사용자가 요청한 정보들을 바탕으로 트래픽을 분산하기 때문에 섬세한 라우팅이 가능하고 비정상적인 트래픽을 판별할 수 있습니다. 하지만, L4 로드 밸런싱보다 비용이 높습니다.

 
